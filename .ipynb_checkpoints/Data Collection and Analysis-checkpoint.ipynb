{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='home'></a>\n",
    "\n",
    "# Table of Content\n",
    "1. Week 1  \n",
    "    1.1 [Research Question](#ques)  \n",
    "    1.2 [Data Generating Process](#dtypes)  \n",
    "    1.3 [Data Curation and Analysis](#cura)  \n",
    "2. [Week 2]  \n",
    "    2.1 [Issues with Inductive Reasoning](#induc)  \n",
    "    2.2 []()\n",
    "3. [week 3]  \n",
    "\n",
    "\n",
    "10. [Reading]()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 1\n",
    "## Research question\n",
    "\n",
    "Steps of Data Analysis\n",
    "1. Research Question\n",
    "2. Data Generation Process\n",
    "3. Data Curation / Storage\n",
    "4. Data Analysis\n",
    "5. Data Output/Access\n",
    "\n",
    "A research question can be separate in three different categories. \n",
    "1. **Descriptive**:  show means, percentages, for certain subgroups. For description, you need is a positive and known selection probability.  \n",
    "2. **Causality** or interest research questions deal with causality: captures all things that have to do with wanting to know whether a certain treatment, for example, taking some pain medication helps. have a positive selection probability of everybody.\n",
    "3. **Predictions**:  have a positive selection probability of everybody.  \n",
    "    \n",
    "All of them rest on some form of data. More likely than not, these data are sample, either in geographic space or in time or because they are subset of the population."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='dtypes'></a>\n",
    "## Types of data\n",
    "what you are try to do in an experiment in the day to day generated process is that you have the systematic variation and nothing else, but that systematic piece variable. They are often smaller in scale and they're specifically designed to answer that particular research question. What's the effect of x on y? X being the treatment, y being my outcome.\n",
    "\n",
    "Features of what we call big data:  \n",
    "1. Volume: For one, they will provide large volume. \n",
    "2. Velocity: Second feature is the velocity. They come in at a high frequency, and that creates an additional analytical challenge.\n",
    "3. Variety: They also come in a wide variety, so here we have timestamps, we have geo coordinates, we have motion measures, and if you think of the big data space in general you can think of even more variety, pictures, sounds, anything can be turned into data.  \n",
    "4. Veracity: The data are also erroneous, or they can be. You might be doubtful about certain elements here in your dataset. You might be missing entire pieces.\n",
    "\n",
    "**[UNECE Big Data Inventory](https://statswiki.unece.org/pages/viewinfo.action?pageId=109250396)**  \n",
    "* Consumer price indices – experimenting with the computation of price indexes\n",
    "* Mobile telephone data – statistics on tourism and daily commuting\n",
    "* Smart meters – statistics on power consumption using data collected from smart\n",
    "meter readings\n",
    "* Traffic loops – traffic statistics using data from traffic loops\n",
    "* Social media – using Twitter data to analyze sentiment and to tourism flows\n",
    "* Job portals – computing statistics on job vacancies\n",
    "* Web scraping – tested methods for automatically collecting data from web sources\n",
    "\n",
    "### The AAPOR Report\n",
    "The American Association for Public Opinion Research (AAPOR) is a professional\n",
    "organization dedicated to advancing the study of “public opinion,” broadly defined, to include\n",
    "attitudes, norms, values, and behaviors.  \n",
    "**Recommendations of the report:**  \n",
    "1. Surveys and Big Data are complementary data sources not competing data sources. There are differences between the approaches, but this should be seen as an advantage rather than a disadvantage. \n",
    "2. AAPOR should develop standards for the use of Big Data in survey research when more knowledge has been accumulated. \n",
    "3. AAPOR should start working with the private sector and other professional organizations to educate its members on Big Data\n",
    "4. AAPOR should inform the public of the risks and benefits of Big Data. \n",
    "5. AAPOR should help remove the barrier associated with different uses of terminology.\n",
    "6. AAPOR should take a leading role in working with federal agencies in developing a necessary infrastructure for the use of Big Data in survey research.\n",
    "\n",
    "**Big Data characteristics**\n",
    "* **Volume:**\n",
    "This refers to the sheer amount of data available for analysis. This volume of data is driven by the increasing number of data collection instruments (e.g., social media tools, mobile applications, sensors) as well as the increased ability to store and transfer those data with recent improvements in data storage and networking.\n",
    "* **Velocity:**\n",
    "This refers to both the speed at which these data collection events can occur, and the pressure of managing large streams of real-time data. Across the means of collecting social information, new information is being added to the database at rates ranging from as slow as every hour or so, to as fast as thousands of events per second.\n",
    "* **Variety:**\n",
    "This refers to the complexity of formats in which Big Data can exist. Besides structured databases, there are large streams of unstructured documents, images, email messages, video, links between devices and other forms that create a heterogeneous set of data points. One effect of this complexity is that structuring and tying data together becomes a major effort, and therefore a central concern of Big Data analysis.\n",
    "\n",
    "The classic statistical paradigm was one in which researchers formulated a hypothesis, identified a population frame, designed a survey and a sampling technique and then analyzed the results. The new paradigm means it is now possible to digitally capture, semantically\n",
    "reconcile, aggregate, and correlate data. These correlations might be effective (Halevy et al. 11 2009, Cukier and Mayer-Schoenberger 2013) or suspect (Couper 2013), but they enable completely new analyses to be undertaken – many of which would not be possible using\n",
    "survey data alone. \n",
    "\n",
    "**Why Bid Data matters**  \n",
    "Recent work shows data driven businesses were 5% more productive and 6% more profitable than their competitors (Brynjolfsson et al. 2011, McAfee and Brynjolfsson 2012). Using data with high volume, velocity, and variety, public opinion researchers can potentially increase the scope of their data collection efforts while at the same time reducing costs, increasing timeliness, and increasing precision (Murphy et al. 2014).\n",
    "\n",
    "Even if data collection is cheap, the costs of cleaning, curating, standardizing, integrating and using the new types of data can be\n",
    "substantial (see Section 5).\n",
    "\n",
    "\n",
    "\n",
    "Data sources:\n",
    "What do you want to know, thinking about that data generating process, who's part of it? What is the measurement? Why were the data generated? What is missing? What is not said? All these possible sources that might prevent this from making valid inference.\n",
    "\n",
    "Paradata:  \n",
    "The process of collecting survey data actually generates also processed data.\n",
    "\n",
    "[Home](#home)\n",
    "\n",
    "<a name='cura'></a>\n",
    "## Data Curation, Storage and Analysis\n",
    "Editing happens everywhere. And the same is of course true with the data that we deal with. There might be, Editing as part of this curation step in the big data process.\n",
    "\n",
    "Depending on the technique, how you do the sample, that distribution can either be wider, or more narrow than the population distribution. It can also be biased, the center being away from the true center.  you need to capture variability correctly in order to provide your estimate of a percentage, the mean or total, or even to talk about the size of a treatment effect or the precision of a prediction\n",
    "\n",
    "## Data Access\n",
    "So much data is publicly available and can be used for the public good. But of course, there are privacy issues and challenging ones that we haven't solved yet. \n",
    "* tension between privacy on the one hand and public goods \n",
    "* Between the convenience versus private companies knowing everything about me\n",
    "* tension that privacy is no longer guaranteed\n",
    "* attention between informed consent, asking people whether they are willing, and purposefully providing the data\n",
    "* tension between privacy and data quality, maybe knowing that these data will be collected, people start misreporting, age for example would be an easy one.\n",
    "\n",
    "### Access Resources\n",
    "What is interesting is that increasingly federal agency and national institutes that collect data, make these data available for researchers in their own country or across the world.\n",
    "* Data Archives in the U.S., ICPSR is a very large one for the social sciences\n",
    "* Data.gov\n",
    "* eurostat\n",
    "* Data without Boundary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 2\n",
    "<a name='induc'></a>\n",
    "## Issues with Inductive Reasoning\n",
    "Induction:  \n",
    "A process of reasoning, used esp in science, by which a general conclusion is drawn from a set of premises, based mainly on experience or experimental evidence. The conclusion goes beyond the information contained in the premises, and does not follow necessarily from them.\n",
    "\n",
    "Challenges:  \n",
    "* Making up a theory that way is an example of affirming the consequent  \n",
    "* We know that inventing the theory by itself proves nothing  \n",
    "\n",
    "## Planning on how to collect data\n",
    "We think about data collection we think about method or mode as having one of the highest impact decisions that you make when you plan your research design. Highest impact because it's heavily related to any error in the data collection and any cost.\n",
    "\n",
    "\n",
    "The decision on which mode to pick, which data source to pick, which methods of data collection you use, should be guided by theory and empirical evidence. The decision on which mode to pick, which data source to pick, which methods of data collection you use, should be guided by theory and empirical evidence.  \n",
    "\n",
    "APIs is an easy way to provide data, or to grab data that is hosted somewhere online. So the data is basically available in export formats e.g. XML, Extensive Markup Language, and JSON the JavaScript Object Notation.  \n",
    "\n",
    "The second, and very different, new data source, are access panels. The advantage of these Access Panels is, they have a large pool of people, and for every given data analysis, for every particular survey you wanna do, there's a smaller group that's taken out of it and the survey is fielded to.  \n",
    "\n",
    "Read up on this Academic Access Panels or another Access Panel and quality of studies that assess their quality that compare those panels with other types of data. You can use the resource, **WebSM** which is a fantastic platform that has almost everything that has been published to this point either referenced here or with a direct link. \n",
    "\n",
    "WebServey:\n",
    "* **Google Consumer Survey**, another very different type of data collection.\n",
    "* **SurveyMonkey or Qualtrics**\n",
    "* **LimeSurvey's**\n",
    "\n",
    "The implications of these choices that you make no matter which data source, or mode, or method of data collection, have\n",
    "an effect on the possible sources of errors of observation and nonobservation.  \n",
    "\n",
    "\n",
    "\n",
    "[Home](#home)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='read'></a>\n",
    "## Reading List\n",
    "1. Week 1:  \n",
    "   * [Japec, L., Kreuter, F., Berg, M., Biemer, P., Decker, P., Lampe, C., ... & Usher, A. (2015). Big Data in Survey Research AAPOR Task Force Report. Public Opinion Quarterly, 79(4), 839-880.](https://www.aapor.org/AAPOR_Main/media/Task-Force-Reports/BigDataTaskForceReport_FINAL_2_12_15_b.pdf)\n",
    "   * [Couper, M. (2013). Is the sky falling? New technology, changing media, and the future of surveys. Survey Research Methods, 7, 145-156.](https://ojs.ub.uni-konstanz.de/srm/article/view/5751/5289)  \n",
    "   \n",
    "   Slides:  \n",
    "   * [Module 1, Part 1 - Research Question Design.pdf](https://d396qusza40orc.cloudfront.net/questionnairedesign/Course%201/Module%201%2C%20Part%201%20-%20Research%20Question%20Design.pdf)\n",
    "   * [Module 1, Part 2 - Types of Data.pdf](https://d396qusza40orc.cloudfront.net/questionnairedesign/Course%201/Module%201%2C%20Part%202%20-%20Types%20of%20Data.pdf)\n",
    "   * [Module 1, Part 3 - Examples of Found Data Use in official statistics.pdf](https://d396qusza40orc.cloudfront.net/questionnairedesign/Course%201/Module%201%2C%20Part%203%20-%20Examples%20of%20Found%20Data%20Use%20in%20official%20statistics.pdf)\n",
    "   * [Module 1, Part 4 - Visualizing the Data Generating Process.pdf](https://d396qusza40orc.cloudfront.net/questionnairedesign/Course%201/Module%201%2C%20Part%204%20-%20Visualizing%20the%20Data%20Generating%20Process.pdf)\n",
    "   * [Module 1, Part 5 - Data Curation.pdf](https://d396qusza40orc.cloudfront.net/questionnairedesign/Course%201/Module%201%2C%20Part%205%20-%20Data%20Curation.pdf)\n",
    "   * [Module 1, Part 6 - Data Analysis.pdf](https://d396qusza40orc.cloudfront.net/questionnairedesign/Course%201/Module%201%2C%20Part%206%20-%20Data%20Analysis.pdf)\n",
    "   * [Module 1, Part 7 - Access Issues.pdf](https://d396qusza40orc.cloudfront.net/questionnairedesign/Course%201/Module%201%2C%20Part%207%20-%20Access%20Issues.pdf)\n",
    "   * [Module 1, Part 8 - Access Ressources.pdf](https://d396qusza40orc.cloudfront.net/questionnairedesign/Course%201/Module%201%2C%20Part%208%20-%20Access%20Ressources.pdf)\n",
    "   * [Module 1, Part 9 - Summary.pdf](https://d396qusza40orc.cloudfront.net/questionnairedesign/Course%201/Module%201%2C%20Part%209%20-%20Summary.pdf)\n",
    "   \n",
    "   \n",
    "2. Week 2:  \n",
    "    * Jäckle, A., Lynn, P., and Burton, J. (2015). Going online with a face-to-face household panel: Effects of a mixed mode design on item and unit. Survey Research Methods, 9, 57-70.\n",
    "\n",
    "3. Week 3:  \n",
    "    * Groves, R. (2011). Three eras of survey research. Public Opinion Quarterly, 75, 861-871. \n",
    "    * Groves, R.M. & Lyberg, L. (2010). Total survey error. Past, present, and future. Public Opinion Quarterly, 74, 849-879.\n",
    "\n",
    "4. Week 4:  \n",
    "    * Davidov, E. (2008). A cross-country and cross-time comparison of the human values measurements with the second round of the European Social Survey. Survey Research Methods, 2, 33-46.\n",
    "    \n",
    "    Module 1, Part 1 - Research Question Design.pdf\n",
    "Module 1, Part 2 - Types of Data.pdf\n",
    "Module 1, Part 3 - Examples of Found Data Use in official statistics.pdf\n",
    "Module 1, Part 4 - Visualizing the Data Generating Process.pdf\n",
    "Module 1, Part 5 - Data Curation.pdf\n",
    "Module 1, Part 6 - Data Analysis.pdf\n",
    "Module 1, Part 7 - Access Issues.pdf\n",
    "Module 1, Part 8 - Access Ressources.pdf\n",
    "Module 1, Part 9 - Summary.pdf\n",
    "\n",
    "\n",
    "### FURTHER RESOURCES:\n",
    "* [Marr, B. (2016). Big Data: 33 Brilliant and Free Data Sources For 2016. Forbes.com](http://www.forbes.com/sites/bernardmarr/2016/02/12/big-data-35-brilliant-and-free-data-sources-for-2016/#cccc05f67961)\n",
    "\n",
    "* A list of sources for big data:  \n",
    "    [Peng, R.D. & Matsui, E. (2015). The Art of Data Science. A Guide for Anyone Who Works with Data. Leanpub](https://leanpub.com/artofdatascience)\n",
    "    \n",
    "* An introduction to statistics and data analysis:  \n",
    "    Jarman, K.H. (2013). The Art of Data Analysis: How to Answer Almost Any Question Using Basic Statistics. New York: Wiley.\n",
    "\n",
    "* An introduction to data analysis: \n",
    "    Jarman, K.H. (2015). Beyond Basic Statistics: Tips, Tricks, and Techniques Every Data Analyst Should Know. New York: Wiley.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
