{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='home'></a>\n",
    "\n",
    "# Table of Content\n",
    "1. Week 1  \n",
    "    1.1 [Research Question](#ques)  \n",
    "    1.2 [Data Generating Process](#dtypes)  \n",
    "    1.3 [Data Curation and Analysis](#cura)  \n",
    "2. [Week 2]  \n",
    "    2.1 [Issues with Inductive Reasoning](#wk2)  \n",
    "    2.2 [Mode of Data Collection](#wk2)  \n",
    "3. [Week 3]  \n",
    "    3.1 [Surveys and Survey Inference](#wk3)  \n",
    "    3.2 [Total Survey Error Framework](#wk3)  \n",
    "    3.3 [How to Quantify Error](#wk3)  \n",
    "4. [Week 4]  \n",
    "    4.1 []()\n",
    "5. [Collection of Sources](#source)\n",
    "10. [Reading]()()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 1\n",
    "## Research question\n",
    "\n",
    "Steps of Data Analysis\n",
    "1. Research Question\n",
    "2. Data Generation Process\n",
    "3. Data Curation / Storage\n",
    "4. Data Analysis\n",
    "5. Data Output/Access\n",
    "\n",
    "A research question can be separate in three different categories. \n",
    "1. **Descriptive**:  show means, percentages, for certain subgroups. For description, you need is a positive and known selection probability.  \n",
    "2. **Causality** or interest research questions deal with causality: captures all things that have to do with wanting to know whether a certain treatment, for example, taking some pain medication helps. have a positive selection probability of everybody.\n",
    "3. **Predictions**:  have a positive selection probability of everybody.  \n",
    "    \n",
    "All of them rest on some form of data. More likely than not, these data are sample, either in geographic space or in time or because they are subset of the population."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='dtypes'></a>\n",
    "## Types of data\n",
    "what you are try to do in an experiment in the day to day generated process is that you have the systematic variation and nothing else, but that systematic piece variable. They are often smaller in scale and they're specifically designed to answer that particular research question. What's the effect of x on y? X being the treatment, y being my outcome.\n",
    "\n",
    "Features of what we call big data:  \n",
    "1. Volume: For one, they will provide large volume. \n",
    "2. Velocity: Second feature is the velocity. They come in at a high frequency, and that creates an additional analytical challenge.\n",
    "3. Variety: They also come in a wide variety, so here we have timestamps, we have geo coordinates, we have motion measures, and if you think of the big data space in general you can think of even more variety, pictures, sounds, anything can be turned into data.  \n",
    "4. Veracity: The data are also erroneous, or they can be. You might be doubtful about certain elements here in your dataset. You might be missing entire pieces.\n",
    "\n",
    "**[UNECE Big Data Inventory](https://statswiki.unece.org/pages/viewinfo.action?pageId=109250396)**  \n",
    "* Consumer price indices – experimenting with the computation of price indexes\n",
    "* Mobile telephone data – statistics on tourism and daily commuting\n",
    "* Smart meters – statistics on power consumption using data collected from smart\n",
    "meter readings\n",
    "* Traffic loops – traffic statistics using data from traffic loops\n",
    "* Social media – using Twitter data to analyze sentiment and to tourism flows\n",
    "* Job portals – computing statistics on job vacancies\n",
    "* Web scraping – tested methods for automatically collecting data from web sources\n",
    "\n",
    "### The AAPOR Report\n",
    "The American Association for Public Opinion Research (AAPOR) is a professional\n",
    "organization dedicated to advancing the study of “public opinion,” broadly defined, to include\n",
    "attitudes, norms, values, and behaviors.  \n",
    "**Recommendations of the report:**  \n",
    "1. Surveys and Big Data are complementary data sources not competing data sources. There are differences between the approaches, but this should be seen as an advantage rather than a disadvantage. \n",
    "2. AAPOR should develop standards for the use of Big Data in survey research when more knowledge has been accumulated. \n",
    "3. AAPOR should start working with the private sector and other professional organizations to educate its members on Big Data\n",
    "4. AAPOR should inform the public of the risks and benefits of Big Data. \n",
    "5. AAPOR should help remove the barrier associated with different uses of terminology.\n",
    "6. AAPOR should take a leading role in working with federal agencies in developing a necessary infrastructure for the use of Big Data in survey research.\n",
    "\n",
    "**Big Data characteristics**\n",
    "* **Volume:**\n",
    "This refers to the sheer amount of data available for analysis. This volume of data is driven by the increasing number of data collection instruments (e.g., social media tools, mobile applications, sensors) as well as the increased ability to store and transfer those data with recent improvements in data storage and networking.\n",
    "* **Velocity:**\n",
    "This refers to both the speed at which these data collection events can occur, and the pressure of managing large streams of real-time data. Across the means of collecting social information, new information is being added to the database at rates ranging from as slow as every hour or so, to as fast as thousands of events per second.\n",
    "* **Variety:**\n",
    "This refers to the complexity of formats in which Big Data can exist. Besides structured databases, there are large streams of unstructured documents, images, email messages, video, links between devices and other forms that create a heterogeneous set of data points. One effect of this complexity is that structuring and tying data together becomes a major effort, and therefore a central concern of Big Data analysis.\n",
    "\n",
    "The classic statistical paradigm was one in which researchers formulated a hypothesis, identified a population frame, designed a survey and a sampling technique and then analyzed the results. The new paradigm means it is now possible to digitally capture, semantically\n",
    "reconcile, aggregate, and correlate data. These correlations might be effective (Halevy et al. 11 2009, Cukier and Mayer-Schoenberger 2013) or suspect (Couper 2013), but they enable completely new analyses to be undertaken – many of which would not be possible using\n",
    "survey data alone. \n",
    "\n",
    "**Why Bid Data matters**  \n",
    "Recent work shows data driven businesses were 5% more productive and 6% more profitable than their competitors (Brynjolfsson et al. 2011, McAfee and Brynjolfsson 2012). Using data with high volume, velocity, and variety, public opinion researchers can potentially increase the scope of their data collection efforts while at the same time reducing costs, increasing timeliness, and increasing precision (Murphy et al. 2014).\n",
    "\n",
    "Even if data collection is cheap, the costs of cleaning, curating, standardizing, integrating and using the new types of data can be\n",
    "substantial (see Section 5).\n",
    "\n",
    "\n",
    "\n",
    "Data sources:\n",
    "What do you want to know, thinking about that data generating process, who's part of it? What is the measurement? Why were the data generated? What is missing? What is not said? All these possible sources that might prevent this from making valid inference.\n",
    "\n",
    "Paradata:  \n",
    "The process of collecting survey data actually generates also processed data.\n",
    "\n",
    "[Home](#home)\n",
    "\n",
    "<a name='cura'></a>\n",
    "## Data Curation, Storage and Analysis\n",
    "Editing happens everywhere. And the same is of course true with the data that we deal with. There might be, Editing as part of this curation step in the big data process.\n",
    "\n",
    "Depending on the technique, how you do the sample, that distribution can either be wider, or more narrow than the population distribution. It can also be biased, the center being away from the true center.  you need to capture variability correctly in order to provide your estimate of a percentage, the mean or total, or even to talk about the size of a treatment effect or the precision of a prediction\n",
    "\n",
    "## Data Access\n",
    "So much data is publicly available and can be used for the public good. But of course, there are privacy issues and challenging ones that we haven't solved yet. \n",
    "* tension between privacy on the one hand and public goods \n",
    "* Between the convenience versus private companies knowing everything about me\n",
    "* tension that privacy is no longer guaranteed\n",
    "* attention between informed consent, asking people whether they are willing, and purposefully providing the data\n",
    "* tension between privacy and data quality, maybe knowing that these data will be collected, people start misreporting, age for example would be an easy one.\n",
    "\n",
    "### Access Resources\n",
    "What is interesting is that increasingly federal agency and national institutes that collect data, make these data available for researchers in their own country or across the world.\n",
    "* Data Archives in the U.S., ICPSR is a very large one for the social sciences\n",
    "* Data.gov\n",
    "* eurostat\n",
    "* Data without Boundary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 2\n",
    "<a name='wk2'></a>\n",
    "## Issues with Inductive Reasoning\n",
    "Induction:  \n",
    "A process of reasoning, used esp in science, by which a general conclusion is drawn from a set of premises, based mainly on experience or experimental evidence. The conclusion goes beyond the information contained in the premises, and does not follow necessarily from them.\n",
    "\n",
    "Challenges:  \n",
    "* Making up a theory that way is an example of affirming the consequent  \n",
    "* We know that inventing the theory by itself proves nothing  \n",
    "\n",
    "## Planning on how to collect data\n",
    "We think about data collection we think about method or mode as having one of the highest impact decisions that you make when you plan your research design. Highest impact because it's heavily related to any error in the data collection and any cost.\n",
    "\n",
    "\n",
    "The decision on which mode to pick, which data source to pick, which methods of data collection you use, should be guided by theory and empirical evidence. The decision on which mode to pick, which data source to pick, which methods of data collection you use, should be guided by theory and empirical evidence.  \n",
    "\n",
    "APIs is an easy way to provide data, or to grab data that is hosted somewhere online. So the data is basically available in export formats e.g. XML, Extensive Markup Language, and JSON the JavaScript Object Notation.  \n",
    "\n",
    "The second, and very different, new data source, are access panels. The advantage of these Access Panels is, they have a large pool of people, and for every given data analysis, for every particular survey you wanna do, there's a smaller group that's taken out of it and the survey is fielded to.  \n",
    "\n",
    "Read up on this Academic Access Panels or another Access Panel and quality of studies that assess their quality that compare those panels with other types of data. You can use the resource, **WebSM** which is a fantastic platform that has almost everything that has been published to this point either referenced here or with a direct link. \n",
    "\n",
    "WebServey:\n",
    "* **Google Consumer Survey**, another very different type of data collection.\n",
    "* **SurveyMonkey or Qualtrics**\n",
    "* **LimeSurvey's**\n",
    "\n",
    "The implications of these choices that you make no matter which data source, or mode, or method of data collection, have\n",
    "an effect on the possible sources of errors of observation and nonobservation.  \n",
    "\n",
    "\n",
    "\n",
    "[Home](#home)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 3\n",
    "<a name='wk3'></a>\n",
    "## Surveys and Survey Inference\n",
    "A good resource to start wherever you are in the world,\n",
    "is the EUROSTAT Handbook on Quality Assessment Methods and Tools. When you think about data quality:\n",
    "* Accuracy\n",
    "* Credibility: It does matter who puts out the data and whether this is seen as a trustworthy entity \n",
    "* Comparability: If interested in long time series or comparing data across countries, you want to make sure you know that you're comparing similar things\n",
    "* Relevance: Invest money in collecting data or designing data and even scraping found data, that are relevant\n",
    "* Completeness: is the data rich enough, so that you can really follow through with the analysis objective\n",
    "\n",
    "There are two types of inference in the survey setting, \n",
    "* one is the inference from a respondent to the characteristic of a respondent\n",
    "* one is the inference from the characteristic of the sample to the characteristic of the population\n",
    "\n",
    "## Total Survey Error Framework\n",
    "Survey Lifecycle: \n",
    "* Lifecycle from a design perspective \n",
    "* the lifecycle from a process perspective\n",
    "* the lifecycle from a quality perspective\n",
    "The measurement links the theoretical construct to the observed variables.  \n",
    "Editing of the responses means that after editing the particular value stored in our data, and recorded so that it can be used for the analysis.  \n",
    "\n",
    "In the first step, you have to design your research objective. You have to choose a mode of data collection and then construct a pretest and a questionnaire.\n",
    "\n",
    "\n",
    "## How to Quantify Error\n",
    "From a quality perspective what we care about is how good does each of these step work. Issues of \n",
    "* validity going from construct to measurement, \n",
    "* measurement error going from measurement to response\n",
    "* Processing error going from response to the edited response\n",
    "* coverage error going from target population to sampling frame. \n",
    "\n",
    "\n",
    "[Home](#home)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='wk4'></a>\n",
    "# Week 4\n",
    "## Example Surveys in the U.S\n",
    "\n",
    "\n",
    "## Cross-Cultural Surveys. \n",
    "\n",
    "\n",
    "[Home](#home)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='source'></a>\n",
    "# Sources\n",
    "  \n",
    "**[World Bank Open Data](https://data.worldbank.org/)**  \n",
    "As a repository of the world’s most comprehensive data regarding what’s happening in different countries across the world, World Bank Open Data is a vital source of Open Data. It also provides access to other datasets as well which are mentioned in the data catalog.\n",
    "You can get access to the API which can help you create the data visualizations you need, live combinations with other data sources and many more such features.  \n",
    "\n",
    "Data types:\n",
    "* [Time Series](https://datacatalog.worldbank.org/search/datasets?sort_by=field_wbddh_modified_date&sort_order=DESC&search_api_views_fulltext_op=AND&f%5B0%5D=field_wbddh_data_type%3A293&f%5B1%5D=type%3Adataset)\n",
    "* [Microdata](https://datacatalog.worldbank.org/search?sort_by=field_wbddh_modified_date&search_api_views_fulltext_op=AND&sort_order=DESC&f[0]=field_wbddh_data_type%3A294)\n",
    "* [Geospatial](https://datacatalog.worldbank.org/search?sort_by=field_wbddh_modified_date&search_api_views_fulltext_op=AND&sort_order=DESC&f[0]=field_wbddh_data_type%3A295)\n",
    "* [API Basic Call Structures](https://datahelpdesk.worldbank.org/knowledgebase/articles/898581-api-basic-call-structures)\n",
    "  \n",
    "**[WHO (World Health Organization)](https://www.who.int/gho/database/en/)**  \n",
    "WHO’s Open Data repository is how WHO keeps track of health-specific statistics of its 194 Member States. The repository keeps the data systematically organized. It can be accessed as per different needs.\n",
    "* [Data query API](https://apps.who.int/gho/data/node.resources.api)\n",
    "* [THE GLOBAL HEALTH OBSERVATORY](https://www.who.int/data/gho)\n",
    "  \n",
    "**[Google Public Data Explorer](https://www.google.com/publicdata/directory)**  \n",
    "Google Public Data Explorer can help you explore vast amounts of public-interest datasets. You can visualize and communicate the data for your respective uses. It makes the data from different agencies and sources available. For instance, you can access data from World Bank, U. S. Bureau of Labor Statistics and U.S. Bureau, OECD, IMF, and others.\n",
    "  \n",
    "**[Registry of Open Data on AWS (RODA)](https://registry.opendata.aws/)**  \n",
    "This is a repository containing public datasets. It is data which is available from AWS resources. As far as RODA is concerned, you can discover and share the data which is publicly available.  \n",
    "* [Examples for all datasets listed](https://registry.opendata.aws/usage-examples/)\n",
    "  \n",
    "**[European Union Open Data Portal](https://data.europa.eu/euodp/en/home)**  \n",
    "The EU Open Data Portal is home to vital open data pertaining to EU policy domains. These policy domains include economy, employment, science, environment, and education. Around 70 EU institutions, organizations or departments such as Eurostat, the European Environment Agency, the Joint Research Centre and other European Commission Directorates General and EU Agencies have made their datasets public and allowed access. \n",
    "* [REST API](https://data.europa.eu/euodp/en/developerscorner)  \n",
    "* [Sample REST requests](https://data.europa.eu/euodp/en/Sample_REST_requests)\n",
    "  \n",
    "**[FiveThirtyEight](https://data.fivethirtyeight.com/)**  \n",
    "In order to render this data user-friendly, it provides datasets in as simple, non-proprietary formats such as CSV files as possible. Needless to say, these formats can be easily accessed and processed by humans as well as machines.\n",
    "With the help of these datasets, you can create stories and visualizations as per your own requirements and preference.\n",
    "  \n",
    "**[U.S. Census Bureau](https://www.census.gov/data.html)**  \n",
    "U.S. Census Bureau is the biggest statistical agency of the federal government. It stores and provides reliable facts and data regarding people, places, and economy of America. The Census Bureau considers its noble mission to extend its services as the most reliable provider of quality data.\n",
    "* [Request Key](https://api.census.gov/data/key_signup.html)\n",
    "* [API Documentation](https://www.census.gov/data/developers.html)\n",
    "  \n",
    "**[Data.gov](https://www.data.gov/)**  \n",
    "Data.gov is the treasure-house of US government’s open data. It was only recently that the decision was made to make all government data available for free. There are now 180,000 datasets. Why Data.gov is a great resource is because you can find data, tools, and resources that you can deploy for a variety of purposes. You can conduct your research, develop your web and mobile applications and even design data visualizations.\n",
    "* [DEVELOPERS APIS](https://www.data.gov/developers/apis)\n",
    "  \n",
    "**[DBpedia]()**  \n",
    "DBpedia aims at getting structured content from the valuable information that Wikipedia created. With DBpedia, you can semantically search and explore relationships and properties of Wikipedia resource. This includes links to other related datasets as well.\n",
    "* []()\n",
    "  \n",
    "**[freeCodeCamp Open Data]()**  \n",
    "It is an open source community. Why it matters is because it enables you to code, build pro bono projects after nonprofits and grab a job as a developer. In order to make this happen, the freeCodeCamp.org community makes available enormous amounts of data every month. They have turned it into open data.\n",
    "  \n",
    "**[Yelp Open Datasets](https://www.yelp.com/dataset)**  \n",
    "  \n",
    "**[UNICEF Dataset](https://data.unicef.org/)**  \n",
    "\n",
    "  \n",
    "**[Kaggle](https://www.kaggle.com/datasets)**  \n",
    "  \n",
    "**[LODUM](https://lodum.de/)** \n",
    "It is the Open Data initiative of the University of Münster. Under this initiative, it is made possible for anyone to access any public information about the university in machine-readable formats. You can easily access and reuse it as per your needs.\n",
    "  \n",
    "**[UCI Machine Learning Repository](https://archive.ics.uci.edu/ml/index.php)**  \n",
    "a comprehensive repository of databases, domain theories, and data generators that are used by the machine learning community for the empirical analysis of machine learning algorithms. In this repository, there are, at present, 463 datasets as a service to the machine learning community.\n",
    "\n",
    "However, please find below a list of other few important open data portals and platforms that permit users to access open data quite easily, study the impact and glean valuable insights.\n",
    "\n",
    "* [Google dataset search](https://toolbox.google.com/datasetsearch)\n",
    "* [Dataverse](https://dataverse.org/)\n",
    "* [Open Data Kit](https://opendatakit.org/)\n",
    "* [Ckan](https://ckan.org/)\n",
    "* [Open Data Monitor](https://opendatamonitor.eu/frontend/web/index.php?r=dashboard%2Findex)\n",
    "* [Plenar.io](http://plenar.io/)\n",
    "* [Open Data Impact Map](http://opendataimpactmap.org/)\n",
    "\n",
    "[Home](#home)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='read'></a>\n",
    "## Reading List\n",
    "1. Week 1:  \n",
    "   * [Japec, L., Kreuter, F., Berg, M., Biemer, P., Decker, P., Lampe, C., ... & Usher, A. (2015). Big Data in Survey Research AAPOR Task Force Report. Public Opinion Quarterly, 79(4), 839-880.](https://www.aapor.org/AAPOR_Main/media/Task-Force-Reports/BigDataTaskForceReport_FINAL_2_12_15_b.pdf)\n",
    "   * [Couper, M. (2013). Is the sky falling? New technology, changing media, and the future of surveys. Survey Research Methods, 7, 145-156.](https://ojs.ub.uni-konstanz.de/srm/article/view/5751/5289)  \n",
    "   \n",
    "   Slides:  \n",
    "   * [Module 1, Part 1 - Research Question Design.pdf](https://d396qusza40orc.cloudfront.net/questionnairedesign/Course%201/Module%201%2C%20Part%201%20-%20Research%20Question%20Design.pdf)\n",
    "   * [Module 1, Part 2 - Types of Data.pdf](https://d396qusza40orc.cloudfront.net/questionnairedesign/Course%201/Module%201%2C%20Part%202%20-%20Types%20of%20Data.pdf)\n",
    "   * [Module 1, Part 3 - Examples of Found Data Use in official statistics.pdf](https://d396qusza40orc.cloudfront.net/questionnairedesign/Course%201/Module%201%2C%20Part%203%20-%20Examples%20of%20Found%20Data%20Use%20in%20official%20statistics.pdf)\n",
    "   * [Module 1, Part 4 - Visualizing the Data Generating Process.pdf](https://d396qusza40orc.cloudfront.net/questionnairedesign/Course%201/Module%201%2C%20Part%204%20-%20Visualizing%20the%20Data%20Generating%20Process.pdf)\n",
    "   * [Module 1, Part 5 - Data Curation.pdf](https://d396qusza40orc.cloudfront.net/questionnairedesign/Course%201/Module%201%2C%20Part%205%20-%20Data%20Curation.pdf)\n",
    "   * [Module 1, Part 6 - Data Analysis.pdf](https://d396qusza40orc.cloudfront.net/questionnairedesign/Course%201/Module%201%2C%20Part%206%20-%20Data%20Analysis.pdf)\n",
    "   * [Module 1, Part 7 - Access Issues.pdf](https://d396qusza40orc.cloudfront.net/questionnairedesign/Course%201/Module%201%2C%20Part%207%20-%20Access%20Issues.pdf)\n",
    "   * [Module 1, Part 8 - Access Ressources.pdf](https://d396qusza40orc.cloudfront.net/questionnairedesign/Course%201/Module%201%2C%20Part%208%20-%20Access%20Ressources.pdf)\n",
    "   * [Module 1, Part 9 - Summary.pdf](https://d396qusza40orc.cloudfront.net/questionnairedesign/Course%201/Module%201%2C%20Part%209%20-%20Summary.pdf)\n",
    "   \n",
    "   \n",
    "2. Week 2:  \n",
    "    * Jäckle, A., Lynn, P., and Burton, J. (2015). Going online with a face-to-face household panel: Effects of a mixed mode design on item and unit. Survey Research Methods, 9, 57-70.\n",
    "\n",
    "3. Week 3:  \n",
    "    * Groves, R. (2011). Three eras of survey research. Public Opinion Quarterly, 75, 861-871. \n",
    "    * Groves, R.M. & Lyberg, L. (2010). Total survey error. Past, present, and future. Public Opinion Quarterly, 74, 849-879.\n",
    "\n",
    "4. Week 4:  \n",
    "    * Davidov, E. (2008). A cross-country and cross-time comparison of the human values measurements with the second round of the European Social Survey. Survey Research Methods, 2, 33-46.\n",
    "    \n",
    "    Module 1, Part 1 - Research Question Design.pdf\n",
    "Module 1, Part 2 - Types of Data.pdf\n",
    "Module 1, Part 3 - Examples of Found Data Use in official statistics.pdf\n",
    "Module 1, Part 4 - Visualizing the Data Generating Process.pdf\n",
    "Module 1, Part 5 - Data Curation.pdf\n",
    "Module 1, Part 6 - Data Analysis.pdf\n",
    "Module 1, Part 7 - Access Issues.pdf\n",
    "Module 1, Part 8 - Access Ressources.pdf\n",
    "Module 1, Part 9 - Summary.pdf\n",
    "\n",
    "\n",
    "### FURTHER RESOURCES:\n",
    "* [Marr, B. (2016). Big Data: 33 Brilliant and Free Data Sources For 2016. Forbes.com](http://www.forbes.com/sites/bernardmarr/2016/02/12/big-data-35-brilliant-and-free-data-sources-for-2016/#cccc05f67961)\n",
    "\n",
    "* A list of sources for big data:  \n",
    "    [Peng, R.D. & Matsui, E. (2015). The Art of Data Science. A Guide for Anyone Who Works with Data. Leanpub](https://leanpub.com/artofdatascience)\n",
    "    \n",
    "* An introduction to statistics and data analysis:  \n",
    "    Jarman, K.H. (2013). The Art of Data Analysis: How to Answer Almost Any Question Using Basic Statistics. New York: Wiley.\n",
    "\n",
    "* An introduction to data analysis: \n",
    "    Jarman, K.H. (2015). Beyond Basic Statistics: Tips, Tricks, and Techniques Every Data Analyst Should Know. New York: Wiley.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
